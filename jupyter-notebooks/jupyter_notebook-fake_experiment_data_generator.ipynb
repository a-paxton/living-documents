{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this workshop, we'll be using\n",
    "some fake data from a fake experiment. This Jupyter\n",
    "notebook contains code to create the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we're interested in seeing how people bond\n",
    "(or build rapport) with one another based on different\n",
    "kinds of conversations. In our fake experiment, we'll ask\n",
    "two strangers to come into the lab and ask them to have\n",
    "a conversation with one another. They'll be randomly \n",
    "assigned to either have a conversation about a really good thing\n",
    "that happened to them in the past week (\"celebration\"\n",
    "conversation) or a really bad thing that happened to them in \n",
    "the past week (\"commiseration\" conversation). \n",
    "Their conversation will be audio- and video-recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that this fake experiment is going to test\n",
    "the similarity of positive emotion words versus negative\n",
    "emotion words that people said during those\n",
    "conversations. We want to see whether partners who use\n",
    "similar negative and/or positive words in these two\n",
    "different kinds of conversations are rated as having\n",
    "higher rapport by expert observers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out negative and positive word similarity,\n",
    "let's say that we transcribed their conversations and\n",
    "simply counted up the number of times per turn that\n",
    "each person used negative words and positive words.\n",
    "We then get the similarity score by taking the correlation\n",
    "of those two scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To track rapport, let's say that we recruited 2\n",
    "expert observers as raters. Let's say that we trained them\n",
    "to continuously rate rapport from the videos using\n",
    "a joystick-style method (cf. Sadler, Ethier, Gunn,\n",
    "Duong, Woody, 2009), creating a time series of ratings between\n",
    "0 and 1. We then obtained a single rapport rating for the dyad\n",
    "by taking the mean of the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means our data will look something like this:\n",
    "* **Dependent variable**: `rapport` (0 to 1; average of \n",
    "    continuous moment-to-moment rating by expert observers)\n",
    "* **Independent variables**: \n",
    "    * `negative_word_similarity` (-1 to +1; correlation \n",
    "        of negative words used by conversation partners)\n",
    "    * `positive_word_similarity` (-1 to +1; correlation \n",
    "        of positive words used by conversation partners)\n",
    "    * `conversation_type` (0 = \"commiseration\" conversation;\n",
    "        1 = \"celebration\" conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Created by**: A. Paxton (University of \n",
    "Connecticut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last modified**: 10 July 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When programming, there are a lot of basic functions (or \n",
    "specific actions that are applied to data; e.g., addition,\n",
    "subtraction) that are built into the core of the language. \n",
    "To expand the power of programming languages, people often\n",
    "write and share additional *libraries* or *packages* that\n",
    "have been developed to incorporate other functions. We\n",
    "have to `import` each additional package or library before\n",
    "we can use those functions, which we do below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import entire libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign shorter names to whole libraries\n",
    "to make typing easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can even just grab specific functions if we\n",
    "don't need the whole package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify how many dyads we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many total dyads do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyad_n = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many commiseration dyads do we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_dyads = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However many we have left over is how many\n",
    "celebration dyads we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_dyads = dyad_n - commiseration_dyads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dyads to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dyad IDs and dataframe for commiseration condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_dyad_IDs = range(1, \n",
    "                               commiseration_dyads+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_dyad_df = pd.DataFrame({'dyad_ID': commiseration_dyad_IDs,\n",
    "                                      'condition': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dyad IDs and dataframe for celebration condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_dyad_IDs = range(commiseration_dyads+1,\n",
    "                             dyad_n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_dyad_df = pd.DataFrame({'dyad_ID': celebration_dyad_IDs,\n",
    "                                   'condition': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly generate rapport variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we rely on random number generation in programming, it's\n",
    "critical to set a seed for our random number generator. This allows\n",
    "us to facilitate *computational reproducibility*, or the ability for\n",
    "us to re-run the code and get precisely the same values. In the\n",
    "case of randomly generated numbers or any programs that incorporate\n",
    "randomness, it's even more important to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that our commiseration mean \n",
    "is higher than the celebration mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_mean = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_sigma = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_mean = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_sigma = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create separate distributions for each rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_rapport = [round(np.random.normal(commiseration_mean,\n",
    "                                                commiseration_sigma), 1)\n",
    "                         for dyad in range(0, commiseration_dyads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_rapport = [round(np.random.normal(celebration_mean,\n",
    "                                              celebration_sigma), 1)\n",
    "                         for dyad in range(0, celebration_dyads)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we add them to the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_dyad_df['rapport'] = commiseration_rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_dyad_df['rapport'] = celebration_rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly create similarity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create them for the commiseration participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_positive = commiseration_dyad_df['rapport']/5 * .25 + [\n",
    "        random.random() for dyad in range(0, commiseration_dyads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_negative = commiseration_dyad_df['rapport']/5 * .75 + [\n",
    "            random.random() for dyad in range(0, commiseration_dyads)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the celebration participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_positive = celebration_dyad_df['rapport']/5 * .5 + [\n",
    "        random.random() for dyad in range(0, celebration_dyads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_negative = celebration_dyad_df['rapport']/5 * .3 + [\n",
    "        random.random() for dyad in range(0, celebration_dyads)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_dyad_df['negative_word_similarity'] = [round(score, 2)\n",
    "                                                     for score in commiseration_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "commiseration_dyad_df['positive_word_similarity'] = [round(score, 2)\n",
    "                                                     for score in commiseration_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_dyad_df['negative_word_similarity'] = [round(score, 2)\n",
    "                                                   for score in celebration_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebration_dyad_df['positive_word_similarity'] = [round(score, 2)\n",
    "                                                   for score in celebration_positive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unified dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created separate subsets for each condition,\n",
    "we'll combine them to create a single experiment dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = commiseration_dyad_df.append(celebration_dyad_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to scale our positive and negative \n",
    "similarity scores, rather than using raw correlations.\n",
    "We have a function that will help us (`scale`),\n",
    "and we can get more information on how to use it by executing\n",
    "this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Standardize a dataset along any axis\n",
       "\n",
       "Center to the mean and component wise scale to unit variance.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : {array-like, sparse matrix}\n",
       "    The data to center and scale.\n",
       "\n",
       "axis : int (0 by default)\n",
       "    axis used to compute the means and standard deviations along. If 0,\n",
       "    independently standardize each feature, otherwise (if 1) standardize\n",
       "    each sample.\n",
       "\n",
       "with_mean : boolean, True by default\n",
       "    If True, center the data before scaling.\n",
       "\n",
       "with_std : boolean, True by default\n",
       "    If True, scale the data to unit variance (or equivalently,\n",
       "    unit standard deviation).\n",
       "\n",
       "copy : boolean, optional, default True\n",
       "    set to False to perform inplace row normalization and avoid a\n",
       "    copy (if the input is already a numpy array or a scipy.sparse\n",
       "    CSC matrix and if axis is 1).\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This implementation will refuse to center scipy.sparse matrices\n",
       "since it would make them non-sparse and would potentially crash the\n",
       "program with memory exhaustion problems.\n",
       "\n",
       "Instead the caller is expected to either set explicitly\n",
       "`with_mean=False` (in that case, only variance scaling will be\n",
       "performed on the features of the CSC matrix) or to call `X.toarray()`\n",
       "if he/she expects the materialized dense array to fit in memory.\n",
       "\n",
       "To avoid memory copy the caller should pass a CSC matrix.\n",
       "\n",
       "For a comparison of the different scalers, transformers, and normalizers,\n",
       "see :ref:`examples/preprocessing/plot_all_scaling.py\n",
       "<sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
       "\n",
       "See also\n",
       "--------\n",
       "StandardScaler: Performs scaling to unit variance using the``Transformer`` API\n",
       "    (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the word similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df['negative_word_similarity_scaled'] = scale(experiment_df['negative_word_similarity'],\n",
    "                                                 axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df['positive_word_similarity_scaled'] = scale(experiment_df['positive_word_similarity'],\n",
    "                                                 axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do our data look now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dyad_ID</th>\n",
       "      <th>condition</th>\n",
       "      <th>rapport</th>\n",
       "      <th>negative_word_similarity</th>\n",
       "      <th>positive_word_similarity</th>\n",
       "      <th>negative_word_similarity_scaled</th>\n",
       "      <th>positive_word_similarity_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>-0.005719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.450721</td>\n",
       "      <td>-0.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.709508</td>\n",
       "      <td>-1.639807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.623246</td>\n",
       "      <td>0.419144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.485870</td>\n",
       "      <td>-1.084217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-1.748970</td>\n",
       "      <td>-0.920808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.239378</td>\n",
       "      <td>-0.495946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-1.058871</td>\n",
       "      <td>0.321098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.442739</td>\n",
       "      <td>1.497641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.615264</td>\n",
       "      <td>-0.234492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-1.015740</td>\n",
       "      <td>1.530323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-2.007758</td>\n",
       "      <td>1.464960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-1.058871</td>\n",
       "      <td>-0.920808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.627559</td>\n",
       "      <td>-1.443717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.183952</td>\n",
       "      <td>-1.214944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.498165</td>\n",
       "      <td>1.007415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.190371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.929477</td>\n",
       "      <td>1.236187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.066853</td>\n",
       "      <td>1.399596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-1.317658</td>\n",
       "      <td>0.419144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.795771</td>\n",
       "      <td>0.059644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.239378</td>\n",
       "      <td>-1.574444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.615264</td>\n",
       "      <td>-1.639807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.917182</td>\n",
       "      <td>0.909370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.451825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.576445</td>\n",
       "      <td>-1.509080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.929477</td>\n",
       "      <td>1.268869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.627559</td>\n",
       "      <td>1.334233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.666377</td>\n",
       "      <td>-0.234492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.191934</td>\n",
       "      <td>-0.136446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.282509</td>\n",
       "      <td>1.334233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.886346</td>\n",
       "      <td>-0.986172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>-0.953490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.800084</td>\n",
       "      <td>0.582552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.838902</td>\n",
       "      <td>0.321098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.278196</td>\n",
       "      <td>0.517189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.493852</td>\n",
       "      <td>0.942052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.886346</td>\n",
       "      <td>-0.103765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-0.282509</td>\n",
       "      <td>-0.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.666377</td>\n",
       "      <td>-0.953490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dyad_ID  condition  rapport  negative_word_similarity  \\\n",
       "0         1          0      0.4                      0.82   \n",
       "1         2          0      0.9                      0.70   \n",
       "2         3          0      0.6                      0.76   \n",
       "3         4          0      0.7                      0.74   \n",
       "4         5          0      0.3                      0.94   \n",
       "5         6          0      0.5                      0.19   \n",
       "6         7          0      0.3                      0.54   \n",
       "7         8          0      0.3                      0.35   \n",
       "8         9          0      0.7                      0.93   \n",
       "9        10          0      0.6                      0.97   \n",
       "10       11          0      0.7                      0.36   \n",
       "11       12          0      0.3                      0.13   \n",
       "12       13          0      0.7                      0.35   \n",
       "13       14          0      0.9                      0.45   \n",
       "14       15          0      0.7                      0.87   \n",
       "15       16          0      0.5                      0.48   \n",
       "16       17          0      0.5                      0.82   \n",
       "17       18          0      0.5                      0.38   \n",
       "18       19          0      0.4                      0.58   \n",
       "19       20          0      0.7                      0.29   \n",
       "20       21          0      0.9                      0.78   \n",
       "21       22          0      0.2                      0.54   \n",
       "22       23          0      0.7                      0.97   \n",
       "23       24          0      0.6                      1.04   \n",
       "24       25          0      0.5                      0.60   \n",
       "25       26          1      0.3                      0.23   \n",
       "26       27          1      0.1                      0.38   \n",
       "27       28          1      0.3                      0.45   \n",
       "28       29          1      0.2                      0.75   \n",
       "29       30          1      0.3                      0.64   \n",
       "30       31          1      0.4                      0.53   \n",
       "31       32          1      0.1                      0.39   \n",
       "32       33          1      0.1                      0.63   \n",
       "33       34          1      0.4                      0.41   \n",
       "34       35          1     -0.1                      0.79   \n",
       "35       36          1      0.3                      0.66   \n",
       "36       37          1      0.2                      0.71   \n",
       "37       38          1      0.2                      0.39   \n",
       "38       39          1      0.2                      0.53   \n",
       "39       40          1      0.4                      0.75   \n",
       "\n",
       "    positive_word_similarity  negative_word_similarity_scaled  \\\n",
       "0                       0.56                         0.968296   \n",
       "1                       0.33                         0.450721   \n",
       "2                       0.06                         0.709508   \n",
       "3                       0.69                         0.623246   \n",
       "4                       0.23                         1.485870   \n",
       "5                       0.28                        -1.748970   \n",
       "6                       0.41                        -0.239378   \n",
       "7                       0.66                        -1.058871   \n",
       "8                       1.02                         1.442739   \n",
       "9                       0.49                         1.615264   \n",
       "10                      1.03                        -1.015740   \n",
       "11                      1.01                        -2.007758   \n",
       "12                      0.28                        -1.058871   \n",
       "13                      0.12                        -0.627559   \n",
       "14                      0.19                         1.183952   \n",
       "15                      0.87                        -0.498165   \n",
       "16                      0.62                         0.968296   \n",
       "17                      0.94                        -0.929477   \n",
       "18                      0.99                        -0.066853   \n",
       "19                      0.69                        -1.317658   \n",
       "20                      0.58                         0.795771   \n",
       "21                      0.08                        -0.239378   \n",
       "22                      0.06                         1.615264   \n",
       "23                      0.84                         1.917182   \n",
       "24                      0.70                         0.019409   \n",
       "25                      0.10                        -1.576445   \n",
       "26                      0.95                        -0.929477   \n",
       "27                      0.97                        -0.627559   \n",
       "28                      0.49                         0.666377   \n",
       "29                      0.52                         0.191934   \n",
       "30                      0.97                        -0.282509   \n",
       "31                      0.26                        -0.886346   \n",
       "32                      0.27                         0.148803   \n",
       "33                      0.74                        -0.800084   \n",
       "34                      0.66                         0.838902   \n",
       "35                      0.72                         0.278196   \n",
       "36                      0.85                         0.493852   \n",
       "37                      0.53                        -0.886346   \n",
       "38                      0.44                        -0.282509   \n",
       "39                      0.27                         0.666377   \n",
       "\n",
       "    positive_word_similarity_scaled  \n",
       "0                         -0.005719  \n",
       "1                         -0.757400  \n",
       "2                         -1.639807  \n",
       "3                          0.419144  \n",
       "4                         -1.084217  \n",
       "5                         -0.920808  \n",
       "6                         -0.495946  \n",
       "7                          0.321098  \n",
       "8                          1.497641  \n",
       "9                         -0.234492  \n",
       "10                         1.530323  \n",
       "11                         1.464960  \n",
       "12                        -0.920808  \n",
       "13                        -1.443717  \n",
       "14                        -1.214944  \n",
       "15                         1.007415  \n",
       "16                         0.190371  \n",
       "17                         1.236187  \n",
       "18                         1.399596  \n",
       "19                         0.419144  \n",
       "20                         0.059644  \n",
       "21                        -1.574444  \n",
       "22                        -1.639807  \n",
       "23                         0.909370  \n",
       "24                         0.451825  \n",
       "25                        -1.509080  \n",
       "26                         1.268869  \n",
       "27                         1.334233  \n",
       "28                        -0.234492  \n",
       "29                        -0.136446  \n",
       "30                         1.334233  \n",
       "31                        -0.986172  \n",
       "32                        -0.953490  \n",
       "33                         0.582552  \n",
       "34                         0.321098  \n",
       "35                         0.517189  \n",
       "36                         0.942052  \n",
       "37                        -0.103765  \n",
       "38                        -0.397900  \n",
       "39                        -0.953490  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.to_csv('../data/simulated_experiment_data.csv',\n",
    "                     sep=',',\n",
    "                     header=True,\n",
    "                     index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
